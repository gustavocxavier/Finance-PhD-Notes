{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "io_breadth.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPb4OSvTqieNC/BG2Z9FW+6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBflx5KsgDiN"
      },
      "source": [
        "# INSTITUTIONAL OWNERSHIP BREADTH\r\n",
        "\r\n",
        "Chen, Hong and Stein (2002) studies the relationship between institutional ownership breadth and underlying stock returns. This set of code replicates this exercise using Thomson Reuters 13F data. The output of this code includes breadth of ownership, institutional ownership relative to total shares, concentration of ownership, etc.\r\n",
        "\r\n",
        "Start by importing Python packages and establishing connection to WRDS server:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELXl-OungC27",
        "outputId": "cd41039b-90e8-45be-9ce2-65552cae1fa3"
      },
      "source": [
        "##################################################\r\n",
        "# Calculate IO, Concentration and Breadth Ratios #\r\n",
        "# Qingyi (Freda) Song Drechsler                  #\r\n",
        "# Date: November 2018                            #\r\n",
        "# Updated: June 2020                             #\r\n",
        "##################################################\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import wrds\r\n",
        "import datetime as dt\r\n",
        "from pandas.tseries.offsets import *\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "###################\r\n",
        "# Connect to WRDS #\r\n",
        "###################\r\n",
        "conn=wrds.Connection()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your WRDS username [root]:gxavier\n",
            "Enter your password:··········\n",
            "WRDS recommends setting up a .pgpass file.\n",
            "You can find more info here:\n",
            "https://www.postgresql.org/docs/9.5/static/libpq-pgpass.html.\n",
            "Loading library list...\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylDFBD5zgzaA"
      },
      "source": [
        "######################################\r\n",
        "# Step 1                             #\r\n",
        "# CRSP Block                         #\r\n",
        "######################################\r\n",
        "\r\n",
        "# set sample date range\r\n",
        "begdate = '03/01/1980'\r\n",
        "enddate = '12/31/2017'\r\n",
        "\r\n",
        "# sql similar to crspmerge macro\r\n",
        "\r\n",
        "crsp_m = conn.raw_sql(f\"\"\"\r\n",
        "                      select a.permno, a.date, \r\n",
        "                      a.ret, a.vol, a.shrout, a.prc, a.cfacpr, a.cfacshr\r\n",
        "                      from crsp.msf as a\r\n",
        "                      left join crsp.msenames as b\r\n",
        "                      on a.permno=b.permno\r\n",
        "                      and b.namedt<=a.date\r\n",
        "                      and a.date<=b.nameendt\r\n",
        "                      where a.date between '{begdate}' and '{enddate}'\r\n",
        "                      and b.shrcd between 10 and 11\r\n",
        "                      \"\"\", date_cols=['date']) \r\n",
        "\r\n",
        "# change variable format to int\r\n",
        "crsp_m[['permno']]= crsp_m[['permno']].astype(int)\r\n",
        "\r\n",
        "# get month and quarter-end dates\r\n",
        "crsp_m['mdate']=crsp_m['date']+pd.offsets.MonthEnd(0)\r\n",
        "crsp_m['qdate']=crsp_m['date']+pd.offsets.QuarterEnd(0)\r\n",
        "\r\n",
        "# calculate adjusted price, total shares and market cap\r\n",
        "crsp_m['p']=crsp_m['prc'].abs()/crsp_m['cfacpr'] # price adjusted\r\n",
        "crsp_m['tso']=crsp_m['shrout']*crsp_m['cfacshr']*1e3 # total shares out adjusted\r\n",
        "crsp_m['me'] = crsp_m['p']*crsp_m['tso']/1e6 # market cap in $mil\r\n",
        "\r\n",
        "# keep only relevant columns\r\n",
        "crsp_m = crsp_m[['permno','mdate','qdate','date','cfacshr', 'p', 'tso','me']]\r\n",
        "\r\n",
        "# For each stock(permno), each quarter (qdate), find the last monthly date (mdate)\r\n",
        "qend = crsp_m[['permno','mdate','qdate']].groupby(['permno','qdate'])['mdate'].max().reset_index()\r\n",
        "\r\n",
        "# Merge back to keep last monthly observation for each quarter\r\n",
        "crsp_qend = pd.merge(crsp_m, qend, how='inner', on=['permno','qdate','mdate'])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIPGGqiVg5OR"
      },
      "source": [
        "######################################\r\n",
        "# Step 2                             #\r\n",
        "# Merge TR 13f s34type1 and s34type3 #\r\n",
        "######################################\r\n",
        "\r\n",
        "fst_vint = conn.raw_sql(\"\"\"\r\n",
        "                      select rdate, fdate, mgrno, mgrname\r\n",
        "                      from tfn.s34type1 \r\n",
        "                      \"\"\", date_cols=['rdate','fdate']) \r\n",
        "\r\n",
        "# Keep first vintage with holding data for each mgrno-rdate combo\r\n",
        "min_fdate = fst_vint.groupby(['mgrno','rdate'])['fdate'].min().reset_index()\r\n",
        "\r\n",
        "# Merge back with the fst_vint data to keep only the first vintage records\r\n",
        "fst_vint = pd.merge(fst_vint, min_fdate, how='inner', on=['mgrno','rdate','fdate'])\r\n",
        "\r\n",
        "# Sort by mgrno and rdate and create lag_rdate to calculate gap\r\n",
        "fst_vint = fst_vint.sort_values(['mgrno', 'rdate'])\r\n",
        "fst_vint['lag_rdate']=fst_vint.groupby(['mgrno'])['rdate'].shift(1)\r\n",
        "\r\n",
        "# Number of quarters gap between rdate and lag_rdate\r\n",
        "fst_vint['rdate_year']=fst_vint.rdate.dt.year\r\n",
        "fst_vint['rdate_qtr'] =fst_vint.rdate.dt.quarter\r\n",
        "\r\n",
        "fst_vint['lag_rdate_year']=fst_vint.lag_rdate.dt.year\r\n",
        "fst_vint['lag_rdate_qtr'] =fst_vint.lag_rdate.dt.quarter\r\n",
        "\r\n",
        "fst_vint['qtr'] = (fst_vint.rdate_year - fst_vint.lag_rdate_year)*4 + (fst_vint.rdate_qtr - fst_vint.lag_rdate_qtr)\r\n",
        "\r\n",
        "\r\n",
        "# label first_report flag\r\n",
        "fst_vint['first_report'] = ((fst_vint.qtr.isnull()) | (fst_vint.qtr>=2))\r\n",
        "fst_vint = fst_vint.drop(['qtr'],axis=1)\r\n",
        "\r\n",
        "# Last report by manager or missing 13F reports in the next quarter(s)\r\n",
        "fst_vint = fst_vint.sort_values(['mgrno','rdate'], ascending=[True, False])\r\n",
        "fst_vint['lead_rdate']=fst_vint.groupby(['mgrno'])['rdate'].shift(1)\r\n",
        "\r\n",
        "# Number of quarters gap between lead_rdate and rdate\r\n",
        "fst_vint['lead_rdate_year']=fst_vint.lead_rdate.dt.year\r\n",
        "fst_vint['lead_rdate_qtr'] =fst_vint.lead_rdate.dt.quarter\r\n",
        "\r\n",
        "fst_vint['qtr'] = (fst_vint.lead_rdate_year - fst_vint.rdate_year)*4 + (fst_vint.lead_rdate_qtr - fst_vint.rdate_qtr)\r\n",
        "\r\n",
        "\r\n",
        "# label last_report flag\r\n",
        "fst_vint['last_report'] = ((fst_vint.qtr.isnull()) | (fst_vint.qtr>=2))\r\n",
        "fst_vint = fst_vint.drop(['qtr'],axis=1)\r\n",
        "\r\n",
        "fst_vint = fst_vint[(fst_vint['rdate']<=enddate) & (fst_vint['rdate']>=begdate)]\\\r\n",
        ".drop(['lag_rdate','lead_rdate'], axis=1)\r\n",
        "\r\n",
        "# Add total number of 13f filers during each quarter\r\n",
        "fst_vint = fst_vint.sort_values(['rdate', 'mgrno'])\r\n",
        "\r\n",
        "NumInst = fst_vint.groupby(['rdate'])['mgrno'].count().reset_index()\\\r\n",
        ".rename(columns={'mgrno':'NumInst'})\r\n",
        "\r\n",
        "fst_vint = pd.merge(fst_vint, NumInst, how='left', on='rdate')\r\n",
        "fst_vint = fst_vint.drop(['mgrname'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdNekDlIg9M3"
      },
      "source": [
        "To make sure share holdings across different quarters are compared on the same basis, we need to gather the shares adjustment factors from CRSP to adjust the holding figures reported in 13F data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-PAURjNg-AJ"
      },
      "source": [
        "######################################\r\n",
        "# Step 3                             #\r\n",
        "# Extract Holdings and Adjust Shares #\r\n",
        "######################################\r\n",
        "\r\n",
        "s34type3 = conn.raw_sql(\"\"\"\r\n",
        "                      select fdate, mgrno, cusip, shares\r\n",
        "                      from tfn.s34type3\r\n",
        "                      \"\"\", date_cols=['fdate']) \r\n",
        "\r\n",
        "holdings_v1 = pd.merge(fst_vint, s34type3, how='inner', on=['fdate','mgrno'] )\r\n",
        "\r\n",
        "# Map 13F's historical cusip to CRSP's permno information\r\n",
        "crsp = conn.raw_sql(\"\"\"\r\n",
        "                    select distinct permno, ncusip\r\n",
        "                    from crsp.msenames\r\n",
        "                    where ncusip != ''\r\n",
        "                    \"\"\")\r\n",
        "\r\n",
        "holdings_v2 = pd.merge(holdings_v1, crsp, how='inner', left_on='cusip', right_on='ncusip')\r\n",
        "holdings_v2 = holdings_v2.drop(['cusip','ncusip'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IgpWP_zhBSJ"
      },
      "source": [
        "Now use shares adjustment factors (cfacshr) to adjust the \"shares\" figure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOWxdYwkhAai"
      },
      "source": [
        "######################################\r\n",
        "# Step 4                             #\r\n",
        "# Adjust Shares Using CRSP CFACSHR   #\r\n",
        "# Align at Vintage Dates             #\r\n",
        "######################################\r\n",
        "\r\n",
        "holdings = pd.merge(holdings_v2, crsp_qend[['qdate','permno','cfacshr']], \\\r\n",
        "                    how='inner', left_on=['permno','fdate'], right_on=['permno','qdate'])\r\n",
        "\r\n",
        "# Calculate Adjusted Shares\r\n",
        "holdings['shares_adj']=holdings['shares']*holdings['cfacshr']\r\n",
        "holdings=holdings.drop(['shares','qdate','cfacshr','fdate'], axis=1)\r\n",
        "\r\n",
        "# Sanity Checks for Duplicates - Ultimately, Should be 0 Duplicates\r\n",
        "holdings = holdings.drop_duplicates(subset=['permno','rdate','mgrno'])\r\n",
        "crsp_qend = crsp_qend.drop_duplicates(subset=['permno','qdate'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFd_vxA1hFuj"
      },
      "source": [
        "With the adjusted portfolio holdings shares ready, now we can calculate various institutional holdings metrics down at security level:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFqDZ5FyhHiW"
      },
      "source": [
        "######################################\r\n",
        "# Step 5                             #\r\n",
        "# Calculate Institutional Measures   #\r\n",
        "# At Security Level                  #\r\n",
        "######################################\r\n",
        "\r\n",
        "holdings = holdings[holdings['shares_adj']>0]\r\n",
        "\r\n",
        "# Number of Owners\r\n",
        "io_numowners = holdings.groupby(['permno','rdate'])['shares_adj'].count().reset_index()\\\r\n",
        ".rename(columns={'shares_adj':'numowners'})\r\n",
        "\r\n",
        "# Number of Institutions\r\n",
        "io_numinst = holdings.groupby(['permno','rdate'])['NumInst'].max().reset_index()\\\r\n",
        ".rename(columns={'NumInst':'numinst'})\r\n",
        "\r\n",
        "# New Old Institutions and Total Shares held by institutions\r\n",
        "io_total = holdings.groupby(['permno','rdate'])['first_report','last_report','shares_adj']\\\r\n",
        ".sum().reset_index()\\\r\n",
        ".rename(columns={'first_report':'newinst', 'last_report':'oldinst','shares_adj':'io_total'})\r\n",
        "io_total.head()\r\n",
        "\r\n",
        "# USS\r\n",
        "tmp = holdings[['permno','rdate','shares_adj']]\r\n",
        "tmp['shares_adj2'] = tmp['shares_adj']**2\r\n",
        "io_uss = tmp.groupby(['permno','rdate'])['shares_adj2'].sum().reset_index()\\\r\n",
        ".rename(columns={'shares_adj2':'io_ss'})\r\n",
        "\r\n",
        "# combine various metrics together\r\n",
        "io_metrics = pd.merge(io_numowners, io_numinst, how='inner', on=['permno','rdate'])\r\n",
        "io_metrics = pd.merge(io_metrics, io_total, how='inner', on =['permno','rdate'])\r\n",
        "io_metrics = pd.merge(io_metrics, io_uss, how='inner', on = ['permno','rdate'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFLhedUChKS1"
      },
      "source": [
        "We follow the Lehavy and Sloan (2008) method to calculate changes in Institutional Breadth: \r\n",
        "\r\n",
        "*   Breadth Condition: institution should exist in Q(t) and Q(t-1)\r\n",
        "*   Objective: Mitigate Bias due to Universe Changes - $100M AUM Filing Threshold\r\n",
        "*   Breadth = ((numinst(t) - newinst(t)) -(numinst(t-1)-oldinst(t-1))) / total number of 13f filers in Q(t-1) where,                                                                             \r\n",
        "    * NewInst(t): Number of 13F filers that reported in t, but did not report in (t-1) \r\n",
        "    * OldInst(t): Number of 13F filers that reported in (t-1), but did not report in t \r\n",
        "    * (NumOwners(t)-NewInst(t)): Number of 13F filers holding security in quarter t, that have reported in both quarters t and t-1                      \r\n",
        "    * (NumOwners(t-1)-OldInst(t-1)): number of 13F filers that held the security in quarter (t-1), and have reported in both quarters t and t-1             "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2fpK0U8hIQy"
      },
      "source": [
        "# Calculate IO DBreadth and Concentration Metrics         \r\n",
        "\r\n",
        "io_metrics['ioc_hhi'] = io_metrics['io_ss']/(io_metrics['io_total']**2)\r\n",
        "io_metrics['d_owner'] = io_metrics['numowners'] - io_metrics['oldinst']\r\n",
        "io_metrics = io_metrics.sort_values(['permno','rdate'])\r\n",
        "\r\n",
        "# Create lag_numinst and lag_d_owner for breadth calculation\r\n",
        "io_metrics['lag_numinst'] = io_metrics.groupby(['permno'])['numinst'].shift(1)\r\n",
        "io_metrics['lag_d_owner'] = io_metrics.groupby(['permno'])['d_owner'].shift(1)\r\n",
        "\r\n",
        "# Calculate change in breadth (dbreath)\r\n",
        "io_metrics['dbreadth'] = ((io_metrics['numowners'] - io_metrics['newinst']) - io_metrics['lag_d_owner'])\\\r\n",
        "/io_metrics['lag_numinst']\r\n",
        "\r\n",
        "# Keep only relevant columns\r\n",
        "io_metrics = io_metrics[['permno','rdate','numowners','io_total','ioc_hhi','dbreadth']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahLf3K15hbd0"
      },
      "source": [
        "Now we add back the CRSP shares outstanding data back, and institutional ownership ratio (IOR) is calculated as total shares owned by institutions divided by total shares outstanding. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-itNPJ5FhgRs"
      },
      "source": [
        "######################################\r\n",
        "# Step 6                             #\r\n",
        "# Add CRSP Market Data to Holdings   #\r\n",
        "# At Calendar Quarter End            #\r\n",
        "######################################\r\n",
        "\r\n",
        "# Note: a right join is necessary to indentify common stocks with no 13F data\r\n",
        "io_ts = pd.merge(io_metrics, crsp_qend[['permno','qdate','p','tso','me']], \\\r\n",
        "                 how='right', left_on=['permno','rdate'], right_on=['permno','qdate'])\r\n",
        "io_ts = io_ts.sort_values(['permno','rdate'])\r\n",
        "\r\n",
        "# keep only records with tso>0\r\n",
        "io_ts = io_ts[io_ts['tso']>0]\r\n",
        "io_ts['ior'] = (io_ts['io_total']/io_ts['tso']).fillna(0)\r\n",
        "io_ts['io_missing'] = np.where(io_ts['rdate'].isna(), 1, 0 )\r\n",
        "io_ts['io_g1'] = np.where(io_ts['ior']>1, 1, 0)\r\n",
        "\r\n",
        "# fill in missing rdate with valid qdate \r\n",
        "io_ts['rdate'] = np.where(io_ts['rdate'].isna(), io_ts['qdate'], io_ts['rdate'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTNbSYyihbWB"
      },
      "source": [
        "Prepare the final table and plots time series of various stats:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXI4hJpEhkZA"
      },
      "source": [
        "######################################\r\n",
        "# Step 7                             #\r\n",
        "# Final Table and Plotting           #\r\n",
        "######################################\r\n",
        "\r\n",
        "# Sanity check for duplicates\r\n",
        "io_ts = io_ts.drop_duplicates(subset=['rdate', 'permno']).sort_values(['rdate','permno'])\r\n",
        "\r\n",
        "# Calculate summary statistics\r\n",
        "\r\n",
        "# ncomps - # of Common Stock Securities in CRSP\r\n",
        "# ncomps_no13f - # of Stocks in CRSP without 13F Data\r\n",
        "io_stats = io_ts.groupby(['rdate']).agg({'ior':'count', 'io_missing':'sum', 'io_g1':'sum'}).reset_index()\\\r\n",
        ".rename(columns={'ior':'ncomps', 'io_missing':'ncomps_no13f', 'io_g1':'sum_io_g1'})\r\n",
        "\r\n",
        "# Medians\r\n",
        "io_median = io_ts.groupby(['rdate'])['ior','ioc_hhi','io_missing'].median().reset_index()\r\n",
        "\r\n",
        "# Combine statistics in one df\r\n",
        "io_stats = pd.merge(io_stats, io_median, how='inner', on='rdate')\r\n",
        "\r\n",
        "# fraction of companies without 13f\r\n",
        "io_stats['io_missing'] = io_stats['ncomps_no13f']/io_stats['ncomps']\r\n",
        "\r\n",
        "# fraction of companies with IOR > 1\r\n",
        "io_stats['io_g1'] = io_stats['sum_io_g1']/io_stats['ncomps']\r\n",
        "io_stats = io_stats.drop('sum_io_g1', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsu72aEjhm3T"
      },
      "source": [
        "We now use the IO metrics produced above to form portfolios and examine the performance:\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x5D-Dhzhn2O"
      },
      "source": [
        "######################################\r\n",
        "# Step 8                             #\r\n",
        "# IO Trends by Size Portfolios       #\r\n",
        "######################################\r\n",
        "\r\n",
        "io_bucket = io_ts\r\n",
        "\r\n",
        "# Assign stocks into quintiles at each quarter based on market cap\r\n",
        "# Exclude Companies with Missing Mktcap Info at Quarter End\r\n",
        "io_bucket['bucket']=io_bucket.groupby('rdate')['me'].transform(lambda x: pd.qcut(x, 5, labels=False))\r\n",
        "io_bucket['bucket']=io_bucket['bucket']+1\r\n",
        "\r\n",
        "# Censor ior at maximum 100%\r\n",
        "io_bucket['ior']=np.where(io_bucket['ior']>1, 1, io_bucket['ior'])\r\n",
        "\r\n",
        "# Caculate IO Mean by Size Bucket\r\n",
        "io_bucket_mean = io_bucket.groupby(['rdate','bucket'])['ior'].mean().reset_index()\r\n",
        "\r\n",
        "# Transpose df for plotting\r\n",
        "io_bucket_ts = io_bucket_mean.pivot(index='rdate', columns='bucket', values='ior').reset_index()\r\n",
        "io_bucket_ts = io_bucket_ts.rename(columns={1.0: 'IOR 1 Small', \\\r\n",
        "                                            2.0: 'IOR 2',\\\r\n",
        "                                            3.0: 'IOR 3',\\\r\n",
        "                                            4.0: 'IOR 4',\\\r\n",
        "                                            5.0: 'IOR 5 Large'})\r\n",
        "\r\n",
        "# Plot Time Series of IO Ratio by Size Quntiles\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(12,8))\r\n",
        "ax = plt.subplot(111)\r\n",
        "plt.style.use('seaborn-whitegrid')\r\n",
        "plt.tick_params(labelsize=14) # set both x and y axes tick size to 14\r\n",
        "plt.xlabel('Report Date', fontsize=14, fontweight='bold')\r\n",
        "plt.title('Time Series of IO Ratio - by Size Buckets \\n Median Statistics', fontsize=18, fontweight='bold')\r\n",
        "\r\n",
        "plt.plot(io_bucket_ts['rdate'], io_bucket_ts['IOR 1 Small'], color='blue', linewidth=4)\r\n",
        "plt.plot(io_bucket_ts['rdate'], io_bucket_ts['IOR 2'], color='red', linewidth=4)\r\n",
        "plt.plot(io_bucket_ts['rdate'], io_bucket_ts['IOR 3'], color='green', linewidth=4)\r\n",
        "plt.plot(io_bucket_ts['rdate'], io_bucket_ts['IOR 4'], color='brown', linewidth=4)\r\n",
        "plt.plot(io_bucket_ts['rdate'], io_bucket_ts['IOR 5 Large'], color='purple', linewidth=4)\r\n",
        "\r\n",
        "\r\n",
        "# Set location of legend box to be outside the chart at bottom\r\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.10),\\\r\n",
        "          fancybox=True, shadow=True, ncol=5, fontsize=14, frameon=True)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}